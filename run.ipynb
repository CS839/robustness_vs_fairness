{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "We are going to compare the accuracy results of gender classifiction across different races. Our hypothesis is that minority groups are likely get affected by the advesarial training more than the majority group\n",
    "## Subsample the dataset without unbalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import UKTFACE as U\n",
    "U.make_csv(\"UTKFace\",\"utkface.csv\")\n",
    "import pandas as pd\n",
    "file=pd.read_csv(\"utkface.csv\")\n",
    "import random\n",
    "index =[i for i in range(len(file))]\n",
    "random.shuffle(index)\n",
    "index = index[:10500]\n",
    "file = file.iloc[index]\n",
    "file.to_csv(\"utkface.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the dataset\n",
    "### On the label attribute gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 2 artists>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "values = np.unique(file.gender,return_counts = True)\n",
    "plt.bar([\"Male\",\"Female\"], values[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On the race attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = np.unique(file.race,return_counts = True)\n",
    "plt.bar([ \"White\", \"Black\", \"Asian\", \"Indian\",\"Others\"], values[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dataset\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from UKTFACE import UKTFace\n",
    "import UKTFACE as U\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from art.attacks import FastGradientMethod\n",
    "from art.classifiers import PyTorchClassifier\n",
    "from art.data_generators import PyTorchDataGenerator\n",
    "\n",
    "from art.defences import AdversarialTrainer\n",
    "# switch device to gpu if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Get dataset with gender labels\n",
    "uktface = UKTFace('utkface.csv', 'UTKFace', labels='gender')\n",
    "\n",
    "# To split training, validation data\n",
    "l = uktface.__len__()\n",
    "training_size = int(np.ceil(l * 0.7))\n",
    "validation_size = int(np.ceil(l * 0.3))\n",
    "train_data, val_data = random_split(uktface, [training_size, validation_size])\n",
    "\n",
    "# to use a data loader\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=False)\n",
    "val_loader = DataLoader(val_data, batch_size=1, shuffle=False)\n",
    "\n",
    "## convert dataloader into datagenerator to make the wrap batch training possible\n",
    "from art.data_generators import PyTorchDataGenerator\n",
    "train_generator = PyTorchDataGenerator(train_loader, len(train_data), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up our baseline classifier\n",
    "min_pixel_value = 0\n",
    "max_pixel_value = 1\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "# Freeze the parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "fc = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(512, 300)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(300, 2)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "model.fc = fc\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model.train(),\n",
    "    clip_values=(min_pixel_value, max_pixel_value),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(3, 224, 224),\n",
    "    nb_classes=2,\n",
    ")\n",
    "\n",
    "\n",
    "## Baseline model training\n",
    "classifier.fit_generator(train_generator, nb_epochs=20)\n",
    "filename_pth = 'ckpt_resnet18_gender.pth'\n",
    "classifier.save(filename_pth,\"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "stat_dic_model = torch.load('models/ckpt_resnet18_gender.pth.model')\n",
    "stat_dic_opt = torch.load('models/ckpt_resnet18_gender.pth.optimizer')\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "criterion = nn.NLLLoss()\n",
    "model = models.resnet18(pretrained=True)\n",
    "# Freeze the parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "fc = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(512, 300)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(300, 2)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "model.fc = fc\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(stat_dic_model)\n",
    "optimizer.load_state_dict(stat_dic_opt)\n",
    "model.load_state_dict(stat_dic_model)\n",
    "optimizer.load_state_dict(stat_dic_opt)\n",
    "classifier = PyTorchClassifier(\n",
    "    model=model.eval(),\n",
    "    clip_values=(min_pixel_value, max_pixel_value),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer,\n",
    "    input_shape=(3, 224, 224),\n",
    "    nb_classes=2,\n",
    ")\n",
    "# Step 5: Compare the results \n",
    "dataset = val_loader.dataset.dataset\n",
    "outputs = []\n",
    "race = []\n",
    "expected = [] \n",
    "index = val_loader.dataset.indices\n",
    "outputs_ad = []\n",
    "for n, (data, label) in enumerate(val_loader):\n",
    "    i = index[n]\n",
    "    race.extend([dataset.get_race(i).item()])\n",
    "    expected.extend(np.array(np.argmax(label,axis=1)))\n",
    "    \n",
    "    output=adclassifier.predict(data)\n",
    "    outputs.extend(np.argmax(output, axis=1))\n",
    "result = sum(np.array(outputs) == np.array(expected))/len(expected)\n",
    "correct = np.array(race)[np.array(outputs) == np.array(expected)]\n",
    "correct = np.unique(correct,return_counts=True)\n",
    "total = np.unique(race, return_counts=True)\n",
    "result_by_race=correct[1]/total[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial Model\n",
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze the parameters\n",
    "for param in model2.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model2.fc = fc\n",
    "model2.to(device)\n",
    "\n",
    "optimizerad = optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "criterionad = nn.NLLLoss()\n",
    "\n",
    "## Defence model training\n",
    "classifier2 = PyTorchClassifier(\n",
    "    model=model2.train(),\n",
    "    clip_values=(min_pixel_value, max_pixel_value),\n",
    "    loss=criterionad,\n",
    "    optimizer=optimizerad,\n",
    "    input_shape=(3, 224, 224),\n",
    "    nb_classes=2,\n",
    ")\n",
    "attack = FastGradientMethod(classifier=classifier, eps=0.1)\n",
    "adclassifier = AdversarialTrainer(classifier2, attack, ratio=0.5)\n",
    "## Defence model training\n",
    "adclassifier.fit_generator(train_generator,nb_epochs=20)\n",
    "filename_pth = 'ckpt_resnet18_gender_defence.pth'\n",
    "#adclassifier.classifier.save(filename_pth,\"models\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "stat_dic_model_ad = torch.load('models/ckpt_resnet18_gender_defence.pth.model')\n",
    "stat_dic_opt_ad = torch.load('models/ckpt_resnet18_gender_defence.pth.optimizer')\n",
    "optimizer2 = optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "criterion = nn.NLLLoss()\n",
    "model2 = models.resnet18(pretrained=True)\n",
    "# Freeze the parameters\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "fc = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(512, 300)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(300, 2)),\n",
    "    ('output', nn.LogSoftmax(dim=1))\n",
    "]))\n",
    "\n",
    "model2.fc = fc\n",
    "model2.to(device)\n",
    "\n",
    "model2.load_state_dict(stat_dic_model_ad)\n",
    "optimizer2.load_state_dict(stat_dic_opt_ad)\n",
    "model2.load_state_dict(stat_dic_model)\n",
    "optimizer2.load_state_dict(stat_dic_opt)\n",
    "adclassifier = PyTorchClassifier(\n",
    "    model=model2.eval(),\n",
    "    clip_values=(min_pixel_value, max_pixel_value),\n",
    "    loss=criterion,\n",
    "    optimizer=optimizer2,\n",
    "    input_shape=(3, 224, 224),\n",
    "    nb_classes=2,\n",
    ")\n",
    "# Step 5: Compare the results \n",
    "dataset = val_loader.dataset.dataset\n",
    "outputs = []\n",
    "race = []\n",
    "expected = [] \n",
    "index = val_loader.dataset.indices\n",
    "outputs_ad = []\n",
    "for n, (data, label) in enumerate(val_loader):\n",
    "    i = index[n]\n",
    "    race.extend([dataset.get_race(i).item()])\n",
    "    expected.extend(np.array(np.argmax(label,axis=1)))\n",
    "    output=adclassifier.predict(data)\n",
    "    outputs.extend(np.argmax(output, axis=1))\n",
    "resultad = sum(np.array(outputs) == np.array(expected))/len(expected)\n",
    "correctad = np.array(race)[np.array(outputs) == np.array(expected)]\n",
    "correctad = np.unique(correctad,return_counts=True)\n",
    "total = np.unique(race, return_counts=True)\n",
    "result_by_race_ad = correctad[1]/total[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial\n",
      "Out of sample accuracy of classification for each race\n",
      "white : 0.809\n",
      "black : 0.812\n",
      "asian : 0.694\n",
      "indian : 0.814\n",
      "others : 0.824\n"
     ]
    }
   ],
   "source": [
    "print(\"Adversarial\")\n",
    "print(\"Out of sample accuracy of classification for each race\")\n",
    "classes = [\"white\", \"black\",\"asian\",'indian','others']\n",
    "for i in range(len(classes)):\n",
    "    print(\"%s : %.3f\"%(classes[i],result_by_race_ad[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline\n",
      "Out of sample accuracy of classification for each race\n",
      "white : 0.667\n",
      "black : 0.605\n",
      "asian : 0.681\n",
      "indian : 0.731\n",
      "others : 0.633\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline\")\n",
    "print(\"Out of sample accuracy of classification for each race\")\n",
    "classes = [\"white\", \"black\",\"asian\",'indian','others']\n",
    "for i in range(len(classes)):\n",
    "    print(\"%s : %.3f\"%(classes[i],result_by_race[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
